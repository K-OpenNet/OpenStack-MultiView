package chainlinker;
import java.util.HashMap;
import java.util.LinkedList;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.json.simple.JSONArray;

/*
 * Not confirmed about what happens when InfluxDB connection failed.
 * No reference or documents are found. Need to be reinforced.
 */

public class SnapParser {
	private static final Logger logger = LogManager.getLogger(SnapParser.class);
//	ConfigLoader.InfluxDBConfig influxDBConf;
	protected Backend backend;

	protected HashMap<String, SnapPluginParser> parserMap = new HashMap<>();
	protected LinkedList<SnapPluginParser> parserList = new LinkedList<>();
	protected ConfigLoader config;

	public SnapParser() {
		config = ConfigLoader.getInstance();
//		influxDBConf = config.getInfluxDBConfig();
		backend = config.getBackend();
		// TODO: Must make this reflective.
		HashMap<String, Class<? extends SnapPluginParser>> parserClassMap = SnapPluginManifest.getInstance().getPluginManifestMap();
		try {
			for (String collector : config.getSnapConfig().getCollectors()) {
				Class<? extends SnapPluginParser> parserClass = parserClassMap.get(collector);
				logger.trace("Loading SnapPluginParser module '" + parserClass.getName() + "' for plugin '" + collector + "'");
				parserList.add(parserClass.newInstance());
			}
		} catch (InstantiationException e) {
			logger.fatal("Failed to instantitate given class from SnapPluginManifest. Is SnapPluginManifest is properly written?", e);
		} catch (IllegalAccessException e) {
			logger.fatal("Failed to instantitate given class from SnapPluginManifest. Is SnapPluginManifest is properly written?", e);
		}
		
		for (SnapPluginParser parserIter : parserList) {
			parserIter.loadParserMap(parserMap);
		}
	}

//	public void processMessage(JSONArray msgValue) {
//		// Creating InfluxDB instance to handle InfluxDB connection
//		logger.trace("Opening a connection to InfluxDB server " + influxDBConf.getAddress() + " with ID " + influxDBConf.getID() + ".");
//		InfluxDB influxDB = InfluxDBFactory.connect(influxDBConf.getAddress(), influxDBConf.getID(), influxDBConf.getPassword());
//		
//		String dbName = influxDBConf.getDBName();
//		influxDB.createDatabase(dbName); // This will be ignored by InfluxDB if already the DB exists
//
//		// Only 1 query are sent to the DB per 1 Kafka message by batching points.
//		logger.trace("Setting up a BatchPoints...");
//		BatchPoints batchPoints = BatchPoints
//				.database(dbName)
//				.retentionPolicy(influxDBConf.getRetentionPolicy())
//				.consistency(influxDBConf.getConsistencyLevel())
//				.build();				
//
//		@SuppressWarnings("unchecked")
//		Iterator<JSONObject> msg_iterator = msgValue.iterator();
//		logger.trace("Processing a message with " + msgValue.size() + " elements.");
//		int count = 1;
//		while (msg_iterator.hasNext()) { // For each data element
//			logger.trace("Processing the element #" + count + ".");
//			JSONObject dataObj = msg_iterator.next();
//			try {
//				batchPoints.point(parse(dataObj));
//			} catch (NullPointerException e) {
//				e.printStackTrace();						
//			} catch (ClassNotFoundException e) {
//				logger.error("Failed to find data type info for given data with field name '" + e.getMessage() + "'", e);
//			}
//			count++;
//		}
//
//		influxDB.write(batchPoints);
//	}
	
	public void processMessage(JSONArray msgValue) {
		backend.processMessage(msgValue, parserMap, parserList);
	}	
	
	
	// Gets each data JSONObject and return it as an Point to be fed into InfluxDB.
//	public Point parse(JSONObject dataObj) throws NullPointerException, ClassNotFoundException {
//		logger.trace("Parsing...");
//		
//		/*
//		 * InfluxDB Format
//		 * 
//		 * Measurement: name
//		 * Tags: source, unit, time
//		 * Field: value
//		 */
//		
//		// Extraction of name.
//		String name = (String)getSafe(dataObj, "namespace");
//		
//		// Extraction of tags.
//		JSONObject tags_json = (JSONObject)getSafe(dataObj, "tags");
//
//		// Extraction of unit.
//		String unit = (String)getSafe(dataObj, "unit");
//
//		// Extraction of time.
//		String timestamp = (String)getSafe(dataObj, "timestamp");
//		long time = RFC3339toNSConvertor.ToNS(timestamp); // TODO: Crash happens!
//
//		logger.trace("Processed a data with time " + timestamp + " = " + time + " ns.");
//
//		org.influxdb.dto.Point.Builder builder = Point.measurement(name)
//				.time(time, TimeUnit.NANOSECONDS);
//		
//		for (Object key : tags_json.keySet()) {
//			// All tags are given as String from Kafka.
//			String tag_name = (String)key;
//			builder.tag(tag_name, (String)tags_json.get(tag_name));
//		}
//		
//		if (unit.length() > 0) {
//			// This prevents 0 length String causing InfluxDB query parsing error.
//			// If any other values make this error again, then more improvements may be required.
//			builder.tag("unit", unit);
//		}
//
//		/*
//		 * Not like previous tag data, the actual value 'data' can't be easily fed into the builder.
//		 * First, there are data type problems. Some value may be float, others may be integer.
//		 * 
//		 * At first glance, field value's data type is never changed, so it would be easy to deal with.
//		 * 
//		 * But it isn't. Especially for float values. Sometimes a float type value would be with
//		 * 0 below point. Then JSONParser will interpret this value as long type and when I try to
//		 * convert it then it will throw type cast error.
//		 * 
//		 * To avert this, these specific values must be casted into long first and then into double.
//		 * But this cannot be applied to all values; long type casting will remove digits below point.
//		 * 
//		 * So I made each parsers know their data type by their namespace in predefined map and
//		 * made this class find appropriate parser for each data by their namespace.  
//		 */
//		
//		// 1st pass : Fast searching for static names via HashMap
//		SnapPluginParser parser = parserMap.get(name);
//		if (parser == null) {
//			// 2nd pass : Querying for parameterized names (ex. snap-plugin-collector-cpu)
//			// Asking all registered parsers whether they can handle given data type
//			for (SnapPluginParser parserIter : parserList) {
//				if (parserIter.isParsible(name)) {
//					parser = parserIter;
//					break;					
//				}
//			}
//		}
//		
//		if (parser == null) {
//			logger.error("No matching parser found with data type '" + name + "'.");
//			throw new ClassNotFoundException (name);
//		}
//		
//		try {
//			parser.addField(builder, name, getSafe(dataObj, "data"));
//		} catch (ClassNotFoundException e) {
//			logger.error("A parser '" + parser.getClass().getName() + "' corresponding to data type '" + name + "', but it does not know how to handle it.");
//			throw new ClassNotFoundException (name);
//		}
//
//		logger.trace("Parsing complete...");
//		return builder.build();
//	}	
}
